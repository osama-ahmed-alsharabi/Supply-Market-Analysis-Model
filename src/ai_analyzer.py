"""
ÙˆØ­Ø¯Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ
ØªØ­Ù„ÙŠÙ„ ÙˆØªÙˆØµÙŠØ§Øª Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ChatGPT
"""

import openai
import pandas as pd
import numpy as np
from typing import Dict, List, Optional
import json


class AIAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©"""
    
    def __init__(self, api_key: str):
        self.client = openai.OpenAI(api_key=api_key)
        self.model = "gpt-4o-mini"
        
    def _create_system_prompt(self) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
        return """Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø³Ù„Ø§Ø³Ù„ Ø§Ù„Ø¥Ù…Ø¯Ø§Ø¯ ÙˆØ§Ù„Ø£Ø³ÙˆØ§Ù‚ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ© Ù„Ù„Ø³Ù„Ø¹ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ø§Ù„Ù‚Ù…Ø­ØŒ Ø§Ù„Ø³ÙƒØ±ØŒ Ø§Ù„Ø²ÙŠØª).

Ù…Ù‡Ù…ØªÙƒ:
1. ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª ÙˆØ§Ù„Ø¥Ù†Ø°Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©
2. ØªÙ‚Ø¯ÙŠÙ… ØªÙˆØµÙŠØ§Øª Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù„Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø± Ù‚Ø¨Ù„ ÙˆÙ‚ÙˆØ¹ Ø§Ù„Ø£Ø²Ù…Ø§Øª
3. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© ÙˆØªØµÙ†ÙŠÙÙ‡Ø§ Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
4. Ø§Ù‚ØªØ±Ø§Ø­ Ø®Ø·Ø· Ø¹Ù…Ù„ ÙˆÙ‚Ø§Ø¦ÙŠØ© Ù…Ù„Ù…ÙˆØ³Ø©

Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©:
- Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ù…Ù‡Ù†ÙŠØ© ÙˆØ§Ø¶Ø­Ø©
- Ù‚Ø¯Ù… ØªÙˆØµÙŠØ§Øª Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙ†ÙÙŠØ°
- Ø§Ø°ÙƒØ± Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª Ø¨ÙˆØ¶ÙˆØ­ (Ø¹Ø§Ù„ÙŠ/Ù…ØªÙˆØ³Ø·/Ù…Ù†Ø®ÙØ¶)
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ§Ù„Ù†Ø³Ø¨ Ù„Ø¯Ø¹Ù… ØªØ­Ù„ÙŠÙ„Ùƒ
- Ù‚Ø¯Ù… Ø¬Ø¯ÙˆÙ„ Ø²Ù…Ù†ÙŠ Ù„Ù„ØªÙ†ÙÙŠØ° Ø­ÙŠØ« Ø£Ù…ÙƒÙ†

Ø£Ù†Øª ØªØ¹Ù…Ù„ Ù„ØµØ§Ù„Ø­ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù‡Ø§Ø¦Ù„ Ø³Ø¹ÙŠØ¯ØŒ Ø¥Ø­Ø¯Ù‰ Ø£ÙƒØ¨Ø± Ø§Ù„Ø´Ø±ÙƒØ§Øª Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ© ÙÙŠ Ø§Ù„ÙŠÙ…Ù† ÙˆØ§Ù„Ù…Ù†Ø·Ù‚Ø©.

Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù„Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©:
1. **Ù…Ù„Ø®Øµ ØªÙ†ÙÙŠØ°ÙŠ** (ÙÙ‚Ø±Ø© ÙˆØ§Ø­Ø¯Ø©)
2. **ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±** (Ù‚Ø§Ø¦Ù…Ø© Ù…Ø±Ù‚Ù…Ø©)
3. **Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©** (Ù‚Ø§Ø¦Ù…Ø© Ù…Ø±Ù‚Ù…Ø© Ù…Ø¹ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©)
4. **Ø®Ø·Ø© Ø§Ù„Ø¹Ù…Ù„** (Ø¬Ø¯ÙˆÙ„ Ø²Ù…Ù†ÙŠ)
5. **Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©** (KPIs)"""

    def _prepare_data_summary(self, predictions_df: pd.DataFrame) -> str:
        """
        ØªØ­Ø¶ÙŠØ± Ù…Ù„Ø®Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„
        Prepare data summary for analysis
        """
        summary = []
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
        total_records = len(predictions_df)
        
        # ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø¨ Ø§Ù„Ø³Ù„Ø¹Ø©
        commodities = predictions_df.groupby('ID_Commodity').agg({
            'Predicted_Landed_Cost': ['mean', 'min', 'max', 'std'],
            'Supply_Alert_Level': lambda x: x.value_counts().to_dict()
        }).round(2)
        
        summary.append(f"ðŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª: {total_records}")
        summary.append(f"\nðŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ Ø­Ø³Ø¨ Ø§Ù„Ø³Ù„Ø¹Ø©:")
        
        for commodity in predictions_df['ID_Commodity'].unique():
            commodity_data = predictions_df[predictions_df['ID_Commodity'] == commodity]
            avg_cost = commodity_data['Predicted_Landed_Cost'].mean()
            max_cost = commodity_data['Predicted_Landed_Cost'].max()
            min_cost = commodity_data['Predicted_Landed_Cost'].min()
            
            # Ø­Ø³Ø§Ø¨ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¥Ù†Ø°Ø§Ø±Ø§Øª
            alert_dist = commodity_data['Supply_Alert_Level'].value_counts()
            high_alerts = alert_dist.get('High', 0)
            med_alerts = alert_dist.get('Med', 0)
            low_alerts = alert_dist.get('Low', 0)
            
            summary.append(f"\n{commodity.upper()}:")
            summary.append(f"  â€¢ Ù…ØªÙˆØ³Ø· Ø§Ù„ØªÙƒÙ„ÙØ©: ${avg_cost:,.0f}/Ø·Ù†")
            summary.append(f"  â€¢ Ù†Ø·Ø§Ù‚ Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ: ${min_cost:,.0f} - ${max_cost:,.0f}")
            summary.append(f"  â€¢ Ø¥Ù†Ø°Ø§Ø±Ø§Øª Ø¹Ø§Ù„ÙŠØ©: {high_alerts} ({high_alerts/len(commodity_data)*100:.1f}%)")
            summary.append(f"  â€¢ Ø¥Ù†Ø°Ø§Ø±Ø§Øª Ù…ØªÙˆØ³Ø·Ø©: {med_alerts}")
            summary.append(f"  â€¢ Ø¥Ù†Ø°Ø§Ø±Ø§Øª Ù…Ù†Ø®ÙØ¶Ø©: {low_alerts}")
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ù†Ø°Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø§Ù„ÙŠØ©
        high_alert_records = predictions_df[predictions_df['Supply_Alert_Level'] == 'High']
        if len(high_alert_records) > 0:
            summary.append(f"\nðŸš¨ Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø¥Ù†Ø°Ø§Ø± Ø§Ù„Ø¹Ø§Ù„ÙŠ ({len(high_alert_records)}):")
            for _, row in high_alert_records.head(5).iterrows():
                summary.append(f"  â€¢ {row['Date']} - {row['ID_Commodity']}: ${row['Predicted_Landed_Cost']:,.0f}")
        
        # Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
        if 'Driver_Cost_Key' in predictions_df.columns:
            top_drivers = predictions_df['Driver_Cost_Key'].value_counts().head(3)
            summary.append(f"\nðŸ”‘ Ø£Ù‡Ù… Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ù…Ø¤Ø«Ø±Ø©:")
            for driver, count in top_drivers.items():
                summary.append(f"  â€¢ {driver}: {count} Ù…Ø±Ø©")
        
        return "\n".join(summary)
    
    def analyze_predictions(self, predictions_df: pd.DataFrame, 
                           commodity_filter: Optional[str] = None) -> Dict:
        """
        ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª ÙˆØªÙ‚Ø¯ÙŠÙ… ØªÙˆØµÙŠØ§Øª
        Analyze predictions and provide recommendations
        
        Parameters:
        -----------
        predictions_df : pd.DataFrame
            Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
        commodity_filter : str, optional
            ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø³Ù„Ø¹Ø© Ù…Ø­Ø¯Ø¯Ø©
            
        Returns:
        --------
        Dict
            Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª
        """
        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„ØªØ± Ø¥Ø°Ø§ ÙˆØ¬Ø¯
        if commodity_filter:
            predictions_df = predictions_df[
                predictions_df['ID_Commodity'] == commodity_filter
            ]
        
        # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…Ù„Ø®Øµ
        data_summary = self._prepare_data_summary(predictions_df)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
        messages = [
            {"role": "system", "content": self._create_system_prompt()},
            {"role": "user", "content": f"""Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ÙˆØªÙ‚Ø¯ÙŠÙ… ØªÙˆØµÙŠØ§Øª Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©:

{data_summary}

Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
1. ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø­Ø§Ù„ÙŠ
2. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ø®Ù„Ø§Ù„ Ø§Ù„ÙØªØ±Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©
3. ØªÙˆØµÙŠØ§Øª Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù„Ù„Ø´Ø±Ø§Ø¡ ÙˆØ§Ù„ØªØ®Ø²ÙŠÙ†
4. Ø®Ø·Ø© Ø¹Ù…Ù„ ÙˆÙ‚Ø§Ø¦ÙŠØ© Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø£Ø²Ù…Ø§Øª
5. Ù…Ø¤Ø´Ø±Ø§Øª Ø£Ø¯Ø§Ø¡ Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©"""}
        ]
        
        try:
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=2000,
                temperature=0.7
            )
            
            analysis_text = response.choices[0].message.content
            
            return {
                "success": True,
                "analysis": analysis_text,
                "data_summary": data_summary,
                "tokens_used": response.usage.total_tokens if response.usage else 0
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "data_summary": data_summary
            }
    
    def get_quick_recommendations(self, predictions_df: pd.DataFrame) -> Dict:
        """
        ØªÙˆØµÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        Quick recommendations based on data
        """
        recommendations = []
        priority_actions = []
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ù†Ø°Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø§Ù„ÙŠØ©
        high_alerts = predictions_df[predictions_df['Supply_Alert_Level'] == 'High']
        high_ratio = len(high_alerts) / len(predictions_df) * 100 if len(predictions_df) > 0 else 0
        
        if high_ratio > 30:
            recommendations.append({
                "type": "critical",
                "title": "âš ï¸ Ù…Ø³ØªÙˆÙ‰ Ø®Ø·Ø± Ù…Ø±ØªÙØ¹",
                "description": f"{high_ratio:.1f}% Ù…Ù† Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª ØªØ´ÙŠØ± Ù„Ø¥Ù†Ø°Ø§Ø±Ø§Øª Ø¹Ø§Ù„ÙŠØ©",
                "action": "ÙŠØ¬Ø¨ Ø§ØªØ®Ø§Ø° Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª ÙÙˆØ±ÙŠØ© Ù„Ù„ØªØ­ÙˆØ·"
            })
            priority_actions.append("Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø®Ø²ÙˆÙ† Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ")
            priority_actions.append("Ø§Ù„ØªÙØ§ÙˆØ¶ Ø¹Ù„Ù‰ Ø¹Ù‚ÙˆØ¯ Ø·ÙˆÙŠÙ„Ø© Ø§Ù„Ø£Ø¬Ù„")
        
        # ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ Ø³Ù„Ø¹Ø©
        for commodity in predictions_df['ID_Commodity'].unique():
            commodity_data = predictions_df[predictions_df['ID_Commodity'] == commodity]
            avg_cost = commodity_data['Predicted_Landed_Cost'].mean()
            max_cost = commodity_data['Predicted_Landed_Cost'].max()
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙ‚Ù„Ø¨
            if len(commodity_data) > 1:
                volatility = commodity_data['Predicted_Landed_Cost'].std() / avg_cost * 100
                
                if volatility > 20:
                    recommendations.append({
                        "type": "warning",
                        "title": f"ðŸ“Š ØªÙ‚Ù„Ø¨ Ø¹Ø§Ù„ÙŠ ÙÙŠ {commodity}",
                        "description": f"Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙ‚Ù„Ø¨: {volatility:.1f}%",
                        "action": f"Ø§Ù„ØªØ­ÙˆØ· Ø¨Ø¹Ù‚ÙˆØ¯ Ø¢Ø¬Ù„Ø© Ù„Ù€ {commodity}"
                    })
            
            # ÙØ­Øµ Ø§Ù„Ø¥Ù†Ø°Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø§Ù„ÙŠØ© Ù„Ù„Ø³Ù„Ø¹Ø©
            high_alerts_commodity = commodity_data[commodity_data['Supply_Alert_Level'] == 'High']
            if len(high_alerts_commodity) > 0:
                recommendations.append({
                    "type": "alert",
                    "title": f"ðŸš¨ Ø¥Ù†Ø°Ø§Ø± Ù„Ù€ {commodity.upper()}",
                    "description": f"{len(high_alerts_commodity)} Ø¥Ù†Ø°Ø§Ø± Ø¹Ø§Ù„ÙŠ ÙÙŠ Ø§Ù„ÙØªØ±Ø©",
                    "action": "Ù…Ø±Ø§Ø¬Ø¹Ø© Ø®Ø·Ø© Ø§Ù„Ø´Ø±Ø§Ø¡"
                })
        
        return {
            "recommendations": recommendations,
            "priority_actions": priority_actions,
            "summary": {
                "total_predictions": len(predictions_df),
                "high_alerts": len(high_alerts),
                "high_ratio": high_ratio
            }
        }
    
    def generate_crisis_prevention_plan(self, predictions_df: pd.DataFrame) -> str:
        """
        ØªÙˆÙ„ÙŠØ¯ Ø®Ø·Ø© Ù…Ù†Ø¹ Ø§Ù„Ø£Ø²Ù…Ø§Øª
        Generate crisis prevention plan
        """
        data_summary = self._prepare_data_summary(predictions_df)
        
        messages = [
            {"role": "system", "content": self._create_system_prompt()},
            {"role": "user", "content": f"""Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©ØŒ Ù‚Ù… Ø¨Ø¥Ø¹Ø¯Ø§Ø¯ Ø®Ø·Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ù…Ù†Ø¹ Ø§Ù„Ø£Ø²Ù…Ø§Øª:

{data_summary}

Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
1. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© (Ø£ÙØ¶Ù„ - Ù…ØªÙˆØ³Ø· - Ø£Ø³ÙˆØ£)
2. Ø®Ø·Ø© Ø·ÙˆØ§Ø±Ø¦ Ù„ÙƒÙ„ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ
3. Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª ÙˆÙ‚Ø§Ø¦ÙŠØ© ÙÙˆØ±ÙŠØ©
4. Ù…Ø¤Ø´Ø±Ø§Øª Ø¥Ù†Ø°Ø§Ø± Ù…Ø¨ÙƒØ±
5. ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠØ§Øª

Ø£Ø¹Ø¯ Ø®Ø·Ø© Ù…Ù†Ø¹ Ø£Ø²Ù…Ø§Øª Ø´Ø§Ù…Ù„Ø© ÙˆÙ‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙ†ÙÙŠØ°."""}
        ]
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=2500,
                temperature=0.6
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø®Ø·Ø©: {str(e)}"


def create_ai_analyzer(api_key: str) -> AIAnalyzer:
    """
    Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ù„Ù„ AI
    Create AI analyzer instance
    """
    return AIAnalyzer(api_key)


if __name__ == "__main__":
    print("=" * 60)
    print("ÙˆØ­Ø¯Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ - AI Analyzer Module")
    print("=" * 60)
    print("\n[OK] Module loaded successfully")
    print("  Ø§Ø³ØªØ®Ø¯Ù… create_ai_analyzer(api_key) Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ù„Ù„")
