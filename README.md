# Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ø±Ø¶ ÙˆØ§Ù„Ø³ÙˆÙ‚
# Supply & Market Analysis Model

<div dir="rtl">

## Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©

Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ø±Ø¶ ÙˆØ§Ù„Ø³ÙˆÙ‚ Ù‡Ùˆ Ù†Ø¸Ø§Ù… ØªØ¹Ù„Ù… Ø¢Ù„ÙŠ Ù…ØªÙ‚Ø¯Ù… Ù…ØµÙ…Ù… Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø± ÙÙŠ Ø³Ù„Ø³Ù„Ø© Ø§Ù„ØªÙˆØ±ÙŠØ¯. ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ **XGBoost** Ù…Ø¹ ØªØ­Ù„ÙŠÙ„ **SHAP** Ù„ØªÙˆÙÙŠØ± ØªÙˆÙ‚Ø¹Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙØ³ÙŠØ±.

</div>

---

## Overview

The Supply & Market Analysis Model is an advanced machine learning system designed to predict costs and analyze risks in the supply chain. The model uses **XGBoost** with **SHAP** analysis to provide accurate and interpretable predictions.

---

<div dir="rtl">

## Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©

1. **Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© Ø¹Ù†Ø¯ Ø§Ù„ÙˆØµÙˆÙ„** (Predicted Landed Cost) - Ø¨Ø§Ù„Ø¯ÙˆÙ„Ø§Ø± Ù„ÙƒÙ„ Ø·Ù†
2. **Ù…Ø³ØªÙˆÙ‰ Ø¥Ù†Ø°Ø§Ø± Ø§Ù„Ø¹Ø±Ø¶** (Supply Alert Level) - Ù…Ù†Ø®ÙØ¶/Ù…ØªÙˆØ³Ø·/Ù…Ø±ØªÙØ¹
3. **Ø§Ù„Ø¹Ø§Ù…Ù„ Ø§Ù„Ø£ÙƒØ«Ø± ØªØ£Ø«ÙŠØ±Ø§Ù‹** (Driver Cost Key) - Ø§Ù„Ù…ÙŠØ²Ø© Ø§Ù„Ø£ÙƒØ«Ø± ØªØ£Ø«ÙŠØ±Ø§Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªÙƒÙ„ÙØ©

</div>

## Key Outputs

1. **Predicted Landed Cost** - in USD per ton
2. **Supply Alert Level** - Low/Med/High
3. **Most Influential Cost Driver** - Feature with highest impact

---

## ğŸ“ Project Structure

```
f:/All Projects/Haeel Saeed Model/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ supply_market_analysis.ipynb    # Main analysis notebook
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py                     # Package initialization
â”‚   â”œâ”€â”€ data_generator.py               # Synthetic data generation
â”‚   â”œâ”€â”€ preprocessing.py                # Data preprocessing
â”‚   â”œâ”€â”€ feature_engineering.py          # Feature creation
â”‚   â”œâ”€â”€ models.py                       # Model training & SHAP
â”‚   â””â”€â”€ utils.py                        # Helper functions
â”œâ”€â”€ data/
â”‚   â””â”€â”€ synthetic_supply_market.csv     # Generated dataset
â”œâ”€â”€ models/
â”‚   â””â”€â”€ xgboost_model.joblib           # Saved trained model
â”œâ”€â”€ output/
â”‚   â””â”€â”€ predictions.csv                 # Model predictions
â”œâ”€â”€ app.py                              # Streamlit dashboard
â”œâ”€â”€ requirements.txt                    # Python dependencies
â””â”€â”€ README.md                           # This file
```

---

## ğŸš€ Quick Start

<div dir="rtl">

### 1. Ø§Ù„ØªØ«Ø¨ÙŠØª - Installation

</div>

```bash
# Clone or navigate to the project directory
cd "f:/All Projects/Haeel Saeed Model"

# Install dependencies
pip install -r requirements.txt
```

<div dir="rtl">

### 2. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - Generate Data

</div>

```bash
# Generate synthetic dataset
python src/data_generator.py
```

This will create `data/synthetic_supply_market.csv` with 5000+ rows of realistic supply chain data.

<div dir="rtl">

### 3. ØªØ´ØºÙŠÙ„ Jupyter Notebook - Run Jupyter Notebook

</div>

```bash
# Start Jupyter
jupyter notebook

# Open: notebooks/supply_market_analysis.ipynb
# Run all cells (Cell -> Run All)
```

The notebook will:
- Load and explore the data
- Apply preprocessing and feature engineering
- Train baseline and XGBoost models
- Generate SHAP analysis
- Export predictions and save the model

<div dir="rtl">

### 4. ØªØ´ØºÙŠÙ„ Dashboard - Run Streamlit Dashboard

</div>

```bash
streamlit run app.py
```

The dashboard will open at `http://localhost:8501` with:
- Overview page with statistics
- Predictions visualization
- Advanced analysis
- New prediction interface

---

## ğŸ“Š Data Schema

<div dir="rtl">

### Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© - Required Columns

</div>

| Column Name | Type | Description (EN) | Ø§Ù„ÙˆØµÙ (AR) |
|-------------|------|------------------|------------|
| `Date` | datetime | Daily date | Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„ÙŠÙˆÙ…ÙŠ |
| `ID_Commodity` | categorical | Commodity type (wheat/sugar/oil) | Ù†ÙˆØ¹ Ø§Ù„Ø³Ù„Ø¹Ø© |
| `Anomaly_Price_Global` | float | Global price with anomalies (USD/ton) | Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ Ù…Ø¹ Ø§Ù„Ø´Ø°ÙˆØ°Ø§Øª |
| `Index_Cost_Shipping` | float | Shipping cost index | Ù…Ø¤Ø´Ø± ØªÙƒÙ„ÙØ© Ø§Ù„Ø´Ø­Ù† |
| `Premium_Insurance_Risk_War` | float | Insurance premium (0-1) | Ø¹Ù„Ø§ÙˆØ© Ø§Ù„ØªØ£Ù…ÙŠÙ†/Ø§Ù„Ù…Ø®Ø§Ø·Ø± |
| `Outlook_Production_Local` | categorical | Local production (low/medium/high) | ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ù…Ø­Ù„ÙŠ |
| `USD_Spread_Price_Market` | float | USD price spread | ÙØ§Ø±Ù‚ Ø³Ø¹Ø± Ø§Ù„Ø¯ÙˆÙ„Ø§Ø± |
| `Index_Stress_Chain_Supply` | float | Supply chain stress (0-100) | Ù…Ø¤Ø´Ø± Ø¥Ø¬Ù‡Ø§Ø¯ Ø§Ù„Ø³Ù„Ø³Ù„Ø© |
| `News_Sentiment_Score` | float | News sentiment (-1 to 1) | ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø± |
| `Customs_Fees_Estimate` | float | Estimated customs fees (USD/ton) | Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¬Ù…Ø±ÙƒÙŠØ© Ø§Ù„ØªÙ‚Ø¯ÙŠØ±ÙŠØ© |

<div dir="rtl">

### Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª - Outputs

</div>

| Column Name | Type | Description |
|-------------|------|-------------|
| `Predicted_Landed_Cost` | float | Predicted cost in USD/ton |
| `Supply_Alert_Level` | categorical | Risk level: Low/Med/High |

---

## ğŸ”„ Using Your Own Data

<div dir="rtl">

### Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙ†Ø§Ø¹ÙŠØ© Ø¨Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ©

1. **ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**: ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù…Ù„Ù CSV Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø£Ø¹Ù„Ø§Ù‡
2. **Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù**: Ø¶Ø¹ Ù…Ù„ÙÙƒ ÙÙŠ `data/your_data.csv`
3. **ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙƒÙˆØ¯**: ÙÙŠ NotebookØŒ ØºÙŠÙ‘Ø±:

</div>

```python
# Instead of:
df = generate_data(n_rows=5000)

# Use:
df = pd.read_csv('data/your_data.csv')
```

<div dir="rtl">

4. **Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**: ØªØ£ÙƒØ¯ Ù…Ù† ØªØ·Ø§Ø¨Ù‚ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ§Ù„Ø£Ù†ÙˆØ§Ø¹
5. **Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨**: Ø´ØºÙ‘Ù„ Ø¬Ù…ÙŠØ¹ Ø®Ù„Ø§ÙŠØ§ Ø§Ù„ Notebook Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

</div>

### Data Sources Recommendations

For production use, consider integrating:

| Data Type | Recommended Sources |
|-----------|---------------------|
| **Global Prices** | Bloomberg, Reuters, Trading Economics |
| **Shipping Costs** | Baltic Exchange, Clarksons Research |
| **News Sentiment** | NewsAPI, Google News API, Twitter API |
| **Customs Data** | Local customs authority APIs |
| **Production Data** | FAO, USDA, local agricultural ministries |
| **Economic Indicators** | World Bank, IMF, central banks |

---

## ğŸ¯ Using the Prediction Function

```python
from src.models import predict_landed_cost

# Predict on new data
results = predict_landed_cost(
    new_data_path='data/new_data.csv',
    model_path='models/xgboost_model.joblib',
    output_path='output/new_predictions.csv'
)

print(results.head())
```

---

## ğŸ“ˆ Model Performance

<div dir="rtl">

### Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©

</div>

Based on synthetic data:

| Metric | Baseline (Linear) | XGBoost |
|--------|------------------|---------|
| **RMSE** | ~80-100 | ~30-50 |
| **MAE** | ~60-80 | ~20-35 |
| **MAPE** | ~8-12% | ~3-6% |
| **RÂ²** | ~0.75-0.85 | ~0.92-0.97 |

> **Note**: Performance on real data may vary significantly.

---

## ğŸ” Feature Importance

<div dir="rtl">

### Ø£Ù‡Ù… Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ù…Ø¤Ø«Ø±Ø©

</div>

Based on SHAP analysis, the most influential features typically are:

1. **Anomaly_Price_Global** - Global commodity prices
2. **Index_Cost_Shipping** - Shipping costs
3. **Index_Stress_Chain_Supply** - Supply chain stress
4. **Premium_Insurance_Risk_War** - Insurance and risk premiums
5. **Price lag features** - Historical price patterns

---

## ğŸ› ï¸ Advanced Features

<div dir="rtl">

### Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª - Feature Engineering

</div>

The model automatically creates:

- **Lag features**: Price 7 and 30 days ago
- **Rolling averages**: 7-day and 30-day moving averages
- **Price ratios**: Current price to moving average
- **Interaction features**: Cross-feature interactions
- **Seasonal features**: Month, quarter, season encoding

<div dir="rtl">

### ØªØ­Ù„ÙŠÙ„ SHAP - SHAP Analysis

</div>

SHAP (SHapley Additive exPlanations) provides:
- Global feature importance
- Individual prediction explanations
- Driver cost key for each prediction

---

## ğŸ“¦ Dependencies

Key libraries used:

- **pandas** >= 1.5.0 - Data manipulation
- **numpy** >= 1.23.0 - Numerical operations
- **scikit-learn** >= 1.2.0 - ML preprocessing and baseline
- **xgboost** >= 1.7.0 - Advanced ML model
- **shap** >= 0.41.0 - Model interpretation
- **streamlit** >= 1.20.0 - Interactive dashboard
- **plotly** >= 5.11.0 - Interactive visualizations
- **matplotlib** >= 3.6.0 - Static visualizations

See `requirements.txt` for complete list.

---

## ğŸ”§ Configuration

<div dir="rtl">

### ØªØ®ØµÙŠØµ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ - Customizing the Model

</div>

Edit hyperparameters in `src/models.py`:

```python
xgb_model = XGBoostModel(random_state=42)
xgb_model.train(
    X_train, y_train, 
    tune_hyperparams=True,  # Enable/disable tuning
    n_iter=20               # Number of search iterations
)
```

Modify parameter ranges in `XGBoostModel.train()` method.

---

## ğŸš¨ Alert Thresholds

<div dir="rtl">

### Ø¹ØªØ¨Ø§Øª Ø§Ù„Ø¥Ù†Ø°Ø§Ø± - Alert Level Thresholds

</div>

Alert levels are based on percentage increase from commodity average:

- **Low**: < 10% above average
- **Med**: 10-20% above average
- **High**: > 20% above average

Customize in `src/utils.py` â†’ `classify_alert_level()`:

```python
alert_levels = classify_alert_level(
    predicted_costs, 
    commodity_groups,
    threshold_med=10,   # Change this
    threshold_high=20   # Change this
)
```

---

## ğŸ“ Output Files

<div dir="rtl">

### Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ø§ØªØ¬Ø©

</div>

After running the notebook:

1. **`models/xgboost_model.joblib`**
   - Trained XGBoost model
   - Used for predictions on new data

2. **`output/predictions.csv`**
   - Predictions for test set
   - Columns: Date, ID_Commodity, Predicted_Landed_Cost, Supply_Alert_Level, Driver_Cost_Key

3. **`data/synthetic_supply_market.csv`**
   - Generated synthetic dataset
   - Replace with your actual data

---

## ğŸ¨ Dashboard Features

<div dir="rtl">

### Ù…ÙŠØ²Ø§Øª Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…

</div>

The Streamlit dashboard (`app.py`) includes:

### ğŸ  Home Page
- Quick statistics overview
- Alert distribution pie chart
- Project information

### ğŸ“ˆ Predictions Page
- Interactive time series plots
- Commodity and alert level filters
- Predictions table with download

### ğŸ” Analysis Page
- Alert distribution by commodity
- Top cost drivers
- Cost statistics by commodity and alert level

### âš¡ New Prediction Page
- CSV file upload for batch predictions
- Manual input form (under development)

---

## ğŸ”„ Workflow

<div dir="rtl">

### Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡

</div>

```mermaid
graph TD
    A[Generate/Load Data] --> B[Preprocess Data]
    B --> C[Feature Engineering]
    C --> D[Train Models]
    D --> E[Evaluate & SHAP Analysis]
    E --> F[Save Model]
    F --> G[Generate Predictions]
    G --> H[Export Results]
    H --> I[Visualize in Dashboard]
    
    J[New Data] --> K[Load Saved Model]
    K --> L[Predict]
    L --> G
```

---

## ğŸ§ª Testing

<div dir="rtl">

### Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙˆØ­Ø¯Ø§Øª

</div>

Test individual modules:

```bash
# Test data generator
python src/data_generator.py

# Test preprocessing
python src/preprocessing.py

# Test feature engineering
python src/feature_engineering.py

# Test utilities
python src/utils.py
```

---

## ğŸŒ Production Deployment

<div dir="rtl">

### Ù†Ø´Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬

</div>

### Option 1: API Deployment

Create a FastAPI/Flask API:

```python
from fastapi import FastAPI, File, UploadFile
from src.models import predict_landed_cost
import pandas as pd

app = FastAPI()

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    df = pd.read_csv(file.file)
    results = predict_landed_cost(df)
    return results.to_dict(orient='records')
```

### Option 2: Scheduled Batch Processing

Use cron/Task Scheduler:

```bash
# Run daily at 6 AM
0 6 * * * cd /path/to/project && python run_daily_predictions.py
```

### Option 3: Cloud Deployment

Deploy dashboard on:
- **Streamlit Cloud** (Free tier available)
- **Heroku**
- **AWS EC2/Lambda**
- **Google Cloud Run**
- **Azure App Service**

---

## ğŸ“š Additional Resources

<div dir="rtl">

### Ù…Ø±Ø§Ø¬Ø¹ Ø¥Ø¶Ø§ÙÙŠØ©

</div>

- **XGBoost Documentation**: https://xgboost.readthedocs.io/
- **SHAP Documentation**: https://shap.readthedocs.io/
- **Streamlit Documentation**: https://docs.streamlit.io/
- **Plotly Documentation**: https://plotly.com/python/

---

## âš ï¸ Important Notes

<div dir="rtl">

### Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù‡Ø§Ù…Ø©

1. **Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙ†Ø§Ø¹ÙŠØ©**: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙÙˆÙ„Ø¯Ø© Ù‡ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª ØµÙ†Ø§Ø¹ÙŠØ© Ù„Ø£ØºØ±Ø§Ø¶ Ø§Ù„ØªÙˆØ¶ÙŠØ­ ÙÙ‚Ø·
2. **Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙØ¹Ù„ÙŠ**: Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù‚Ø¯ ÙŠØ®ØªÙ„Ù
3. **Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¯ÙˆØ±ÙŠ**: ÙŠÙÙ†ØµØ­ Ø¨Ø¥Ø¹Ø§Ø¯Ø© ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙƒÙ„ 3-6 Ø£Ø´Ù‡Ø±
4. **Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„ÙŠØ¯ÙˆÙŠ**: ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ù…Ø®Ø§Ø·Ø± ÙŠØ¯ÙˆÙŠØ§Ù‹ Ù‚Ø¨Ù„ Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª
5. **Ø§Ù„Ø£Ù…Ø§Ù†**: Ù„Ø§ ØªØ´Ø§Ø±Ùƒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø¹Ù„Ù†Ø§Ù‹

</div>

---

## ğŸ¤ Contributing

<div dir="rtl">

### Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø© ÙÙŠ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹

</div>

To improve this model:

1. Add more data sources
2. Implement additional models (LSTM, Prophet)
3. Enhance the dashboard
4. Add automated testing
5. Improve documentation

---

## ğŸ“§ Support

<div dir="rtl">

### Ø§Ù„Ø¯Ø¹Ù…

Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø£Ùˆ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„:
1. Ø±Ø§Ø¬Ø¹ Ø§Ù„ØªÙˆØ«ÙŠÙ‚ ÙÙŠ Notebook
2. ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ØµØ¯Ø±ÙŠ ÙÙŠ `src/`
3. ØªØ£ÙƒØ¯ Ù…Ù† ØªØ·Ø§Ø¨Ù‚ Ù…Ø®Ø·Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

</div>

For questions or issues:
1. Review the documentation in the notebook
2. Check source code files in `src/`
3. Verify data schema compatibility

---

## ğŸ“„ License

<div dir="rtl">

Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ù…ÙØªÙˆØ­ Ø§Ù„Ù…ØµØ¯Ø± ÙˆÙ…ØªØ§Ø­ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ§Ù„ØªØ¹Ø¯ÙŠÙ„.

</div>

This project is open source and available for use and modification.

---

<div dir="rtl">

## ğŸ¯ Next Steps

### Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡Ø§:

1. **Ø¬Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ©** Ù…Ù† Ø§Ù„Ø¬Ù…Ø§Ø±Ùƒ ÙˆØ§Ù„Ù…ÙˆØ§Ù†Ø¦
2. **Ø±Ø¨Ø· APIs** Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­ÙŠØ© (Ø£Ø³Ø¹Ø§Ø±ØŒ Ø£Ø®Ø¨Ø§Ø±ØŒ Ø·Ù‚Ø³)
3. **ØªØ·ÙˆÙŠØ± API** Ù„Ù„ØªÙ†Ø¨Ø¤ ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„ÙØ¹Ù„ÙŠ
4. **Ø¥Ø¹Ø¯Ø§Ø¯ ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø¢Ù„ÙŠØ©** Ø¹Ø¨Ø± Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø£Ùˆ SMS
5. **Ø¯Ù…Ø¬ Ù…Ø¹ Ø£Ù†Ø¸Ù…Ø© ERP/SCM** Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
6. **Ø¥Ø¶Ø§ÙØ© ØªØ­Ù„ÙŠÙ„ NLP** Ù„Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©
7. **Ø¨Ù†Ø§Ø¡ Ù†Ù…Ø§Ø°Ø¬ ØªÙˆÙ‚Ø¹ Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø®Ø·ÙˆØ§Øª** Ù„Ù„Ø£Ø³Ø§Ø¨ÙŠØ¹ Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©

</div>

### Recommended Next Steps:

1. **Collect real data** from customs and ports
2. **Integrate APIs** for live data (prices, news, weather)
3. **Develop prediction API** for real-time forecasting
4. **Setup automated alerts** via email or SMS
5. **Integrate with existing ERP/SCM** systems
6. **Add NLP analysis** for economic news
7. **Build multi-step forecasting** models for upcoming weeks

---

<div align="center">

**Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ø±Ø¶ ÙˆØ§Ù„Ø³ÙˆÙ‚**  
**Supply & Market Analysis Model**

Built with â¤ï¸ using Python, XGBoost, and SHAP

</div>
